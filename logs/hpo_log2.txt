nohup: ignoring input
/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/torch/cuda/__init__.py:61: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
  import pynvml  # type: ignore[import]
[I 2025-12-13 05:49:25,385] A new study created in memory with name: no-name-bbf2f7ac-d9c5-4ea0-8cd5-7bd4c3049eba
사용 장치: cuda
Epoch 1/15
----------
train Loss: 0.4309 Acc: 0.8594
val Loss: 0.2710 Acc: 0.9084
Epoch 2/15
----------
train Loss: 0.2684 Acc: 0.9076
val Loss: 0.2311 Acc: 0.9204
Epoch 3/15
----------
train Loss: 0.2400 Acc: 0.9164
val Loss: 0.2125 Acc: 0.9269
Epoch 4/15
----------
train Loss: 0.2249 Acc: 0.9216
val Loss: 0.2045 Acc: 0.9295
Epoch 5/15
----------
train Loss: 0.2163 Acc: 0.9246
val Loss: 0.1963 Acc: 0.9320
Epoch 6/15
----------
train Loss: 0.2109 Acc: 0.9267
val Loss: 0.1909 Acc: 0.9349
Epoch 7/15
----------
train Loss: 0.2063 Acc: 0.9273
val Loss: 0.1890 Acc: 0.9354
성능 향상 X, 스탑 카운터 : 1
Epoch 8/15
----------
train Loss: 0.2023 Acc: 0.9285
val Loss: 0.1858 Acc: 0.9360
Epoch 9/15
----------
train Loss: 0.1998 Acc: 0.9295
val Loss: 0.1826 Acc: 0.9378
Epoch 10/15
----------
train Loss: 0.1954 Acc: 0.9318
val Loss: 0.1819 Acc: 0.9379
성능 향상 X, 스탑 카운터 : 1
Epoch 11/15
----------
train Loss: 0.1954 Acc: 0.9315
val Loss: 0.1816 Acc: 0.9378
성능 향상 X, 스탑 카운터 : 2
Epoch 12/15
----------
train Loss: 0.1953 Acc: 0.9317
val Loss: 0.1812 Acc: 0.9377
성능 향상 X, 스탑 카운터 : 3
Epoch 13/15
----------
train Loss: 0.1949 Acc: 0.9314
[I 2025-12-13 06:40:18,008] Trial 0 finished with value: 0.9378085398748027 and parameters: {'lr': 0.00036454275173181106, 'model_name': 'convnext_tiny', 'epochs': 18, 'jitter_strength': 0.12253107929080742, 'scheduler_step': 9, 'weight_decay': 3.283989050344232e-06, 'optimizer': 'AdamW'}. Best is trial 0 with value: 0.9378085398748027.
val Loss: 0.1811 Acc: 0.9380
성능 향상 X, 스탑 카운터 : 4

--- 얼리 스탑: 4 에폭 동안 성능 향상이 없어 훈련을 중단합니다. ---
Training complete in 50m 52s
Best val Acc: 0.9378
Epoch 1/15
----------
train Loss: 1.3364 Acc: 0.5362
val Loss: 0.9829 Acc: 0.7251
Epoch 2/15
----------
train Loss: 0.8512 Acc: 0.7535
val Loss: 0.7380 Acc: 0.7818
Epoch 3/15
----------
train Loss: 0.6864 Acc: 0.7881
val Loss: 0.6329 Acc: 0.8022
Epoch 4/15
----------
train Loss: 0.6035 Acc: 0.8051
val Loss: 0.5704 Acc: 0.8176
Epoch 5/15
----------
train Loss: 0.5718 Acc: 0.8124
val Loss: 0.5585 Acc: 0.8198
Epoch 6/15
----------
train Loss: 0.5661 Acc: 0.8146
val Loss: 0.5574 Acc: 0.8199
성능 향상 X, 스탑 카운터 : 1
Epoch 7/15
----------
train Loss: 0.5614 Acc: 0.8147
val Loss: 0.5515 Acc: 0.8215
Epoch 8/15
----------
train Loss: 0.5566 Acc: 0.8175
val Loss: 0.5476 Acc: 0.8218
성능 향상 X, 스탑 카운터 : 1
Epoch 9/15
----------
train Loss: 0.5547 Acc: 0.8164
val Loss: 0.5455 Acc: 0.8208
성능 향상 X, 스탑 카운터 : 2
Epoch 10/15
----------
train Loss: 0.5538 Acc: 0.8166
val Loss: 0.5473 Acc: 0.8228
Epoch 11/15
----------
train Loss: 0.5538 Acc: 0.8172
val Loss: 0.5485 Acc: 0.8220
성능 향상 X, 스탑 카운터 : 1
Epoch 12/15
----------
train Loss: 0.5523 Acc: 0.8177
val Loss: 0.5502 Acc: 0.8215
성능 향상 X, 스탑 카운터 : 2
Epoch 13/15
----------
train Loss: 0.5526 Acc: 0.8169
val Loss: 0.5456 Acc: 0.8233
성능 향상 X, 스탑 카운터 : 3
Epoch 14/15
----------
train Loss: 0.5523 Acc: 0.8182
[I 2025-12-13 07:32:56,491] Trial 1 finished with value: 0.8227899638658456 and parameters: {'lr': 1.516791423352885e-05, 'model_name': 'resnet50', 'epochs': 18, 'jitter_strength': 0.16577337721467747, 'scheduler_step': 4, 'weight_decay': 0.00017974715926928554, 'optimizer': 'AdamW'}. Best is trial 0 with value: 0.9378085398748027.
val Loss: 0.5447 Acc: 0.8237
성능 향상 X, 스탑 카운터 : 4

--- 얼리 스탑: 4 에폭 동안 성능 향상이 없어 훈련을 중단합니다. ---
Training complete in 52m 38s
Best val Acc: 0.8228
Epoch 1/15
----------
train Loss: 0.4230 Acc: 0.8609
val Loss: 0.2643 Acc: 0.9094
Epoch 2/15
----------
train Loss: 0.2614 Acc: 0.9097
val Loss: 0.2266 Acc: 0.9213
Epoch 3/15
----------
train Loss: 0.2351 Acc: 0.9177
val Loss: 0.2089 Acc: 0.9277
Epoch 4/15
----------
train Loss: 0.2217 Acc: 0.9220
val Loss: 0.2000 Acc: 0.9307
Epoch 5/15
----------
train Loss: 0.2133 Acc: 0.9256
val Loss: 0.1937 Acc: 0.9326
Epoch 6/15
----------
train Loss: 0.2083 Acc: 0.9265
val Loss: 0.1915 Acc: 0.9327
성능 향상 X, 스탑 카운터 : 1
Epoch 7/15
----------
train Loss: 0.2042 Acc: 0.9281
val Loss: 0.1849 Acc: 0.9368
Epoch 8/15
----------
train Loss: 0.2014 Acc: 0.9294
val Loss: 0.1828 Acc: 0.9378
성능 향상 X, 스탑 카운터 : 1
Epoch 9/15
----------
train Loss: 0.1959 Acc: 0.9317
val Loss: 0.1822 Acc: 0.9383
Epoch 10/15
----------
train Loss: 0.1956 Acc: 0.9318
val Loss: 0.1818 Acc: 0.9381
성능 향상 X, 스탑 카운터 : 1
Epoch 11/15
----------
train Loss: 0.1948 Acc: 0.9314
val Loss: 0.1815 Acc: 0.9381
성능 향상 X, 스탑 카운터 : 2
Epoch 12/15
----------
train Loss: 0.1946 Acc: 0.9318
val Loss: 0.1813 Acc: 0.9382
성능 향상 X, 스탑 카운터 : 3
Epoch 13/15
----------
train Loss: 0.1942 Acc: 0.9318
[I 2025-12-13 08:23:57,680] Trial 2 finished with value: 0.9383174716270547 and parameters: {'lr': 0.0004093780590349415, 'model_name': 'convnext_tiny', 'epochs': 19, 'jitter_strength': 0.18416142389492823, 'scheduler_step': 8, 'weight_decay': 0.00020226874933662047, 'optimizer': 'AdamW'}. Best is trial 2 with value: 0.9383174716270547.
Downloading: "https://download.pytorch.org/models/mobilenet_v3_large-8738ca79.pth" to /home/ec2-user/.cache/torch/hub/checkpoints/mobilenet_v3_large-8738ca79.pth
val Loss: 0.1809 Acc: 0.9386
성능 향상 X, 스탑 카운터 : 4

--- 얼리 스탑: 4 에폭 동안 성능 향상이 없어 훈련을 중단합니다. ---
Training complete in 51m 1s
Best val Acc: 0.9383
  0%|                                                                                                                          | 0.00/21.1M [00:00<?, ?B/s]100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 21.1M/21.1M [00:00<00:00, 230MB/s]
Epoch 1/15
----------
train Loss: 0.9524 Acc: 0.7045
val Loss: 0.6225 Acc: 0.7980
Epoch 2/15
----------
train Loss: 0.5865 Acc: 0.8026
val Loss: 0.5154 Acc: 0.8254
Epoch 3/15
----------
train Loss: 0.5202 Acc: 0.8203
val Loss: 0.4700 Acc: 0.8382
Epoch 4/15
----------
train Loss: 0.4872 Acc: 0.8294
val Loss: 0.4450 Acc: 0.8469
Epoch 5/15
----------
train Loss: 0.4684 Acc: 0.8347
val Loss: 0.4275 Acc: 0.8516
Epoch 6/15
----------
train Loss: 0.4550 Acc: 0.8378
val Loss: 0.4152 Acc: 0.8544
Epoch 7/15
----------
train Loss: 0.4472 Acc: 0.8412
val Loss: 0.4069 Acc: 0.8566
Epoch 8/15
----------
train Loss: 0.4404 Acc: 0.8426
val Loss: 0.3996 Acc: 0.8601
Epoch 9/15
----------
train Loss: 0.4341 Acc: 0.8447
val Loss: 0.3982 Acc: 0.8608
성능 향상 X, 스탑 카운터 : 1
Epoch 10/15
----------
train Loss: 0.4334 Acc: 0.8457
val Loss: 0.3992 Acc: 0.8599
성능 향상 X, 스탑 카운터 : 2
Epoch 11/15
----------
train Loss: 0.4327 Acc: 0.8463
val Loss: 0.3979 Acc: 0.8600
성능 향상 X, 스탑 카운터 : 3
Epoch 12/15
----------
train Loss: 0.4315 Acc: 0.8450
[I 2025-12-13 08:45:32,869] Trial 3 finished with value: 0.860145554481144 and parameters: {'lr': 8.822162168070044e-05, 'model_name': 'mobilenet_v3', 'epochs': 12, 'jitter_strength': 0.2871570283032898, 'scheduler_step': 8, 'weight_decay': 8.76134797535049e-06, 'optimizer': 'Adam'}. Best is trial 2 with value: 0.9383174716270547.
val Loss: 0.3967 Acc: 0.8611
성능 향상 X, 스탑 카운터 : 4

--- 얼리 스탑: 4 에폭 동안 성능 향상이 없어 훈련을 중단합니다. ---
Training complete in 21m 35s
Best val Acc: 0.8601
Epoch 1/15
----------
train Loss: 0.3691 Acc: 0.8765
val Loss: 0.2408 Acc: 0.9164
Epoch 2/15
----------
train Loss: 0.2431 Acc: 0.9158
val Loss: 0.2115 Acc: 0.9267
Epoch 3/15
----------
train Loss: 0.2214 Acc: 0.9225
val Loss: 0.1973 Acc: 0.9323
Epoch 4/15
----------
train Loss: 0.2118 Acc: 0.9247
val Loss: 0.1904 Acc: 0.9333
성능 향상 X, 스탑 카운터 : 1
Epoch 5/15
----------
train Loss: 0.2037 Acc: 0.9279
val Loss: 0.1859 Acc: 0.9356
Epoch 6/15
----------
train Loss: 0.2004 Acc: 0.9292
val Loss: 0.1821 Acc: 0.9367
Epoch 7/15
----------
train Loss: 0.1972 Acc: 0.9299
val Loss: 0.1818 Acc: 0.9368
성능 향상 X, 스탑 카운터 : 1
Epoch 8/15
----------
train Loss: 0.1943 Acc: 0.9316
val Loss: 0.1782 Acc: 0.9391
Epoch 9/15
----------
train Loss: 0.1930 Acc: 0.9318
val Loss: 0.1762 Acc: 0.9399
성능 향상 X, 스탑 카운터 : 1
Epoch 10/15
----------
train Loss: 0.1883 Acc: 0.9334
val Loss: 0.1743 Acc: 0.9407
Epoch 11/15
----------
train Loss: 0.1869 Acc: 0.9341
val Loss: 0.1738 Acc: 0.9398
성능 향상 X, 스탑 카운터 : 1
Epoch 12/15
----------
train Loss: 0.1865 Acc: 0.9340
val Loss: 0.1739 Acc: 0.9410
성능 향상 X, 스탑 카운터 : 2
Epoch 13/15
----------
train Loss: 0.1866 Acc: 0.9344
val Loss: 0.1738 Acc: 0.9408
성능 향상 X, 스탑 카운터 : 3
Epoch 14/15
----------
train Loss: 0.1859 Acc: 0.9352
[I 2025-12-13 09:40:39,926] Trial 4 finished with value: 0.940658557687414 and parameters: {'lr': 0.0006365221565212788, 'model_name': 'convnext_tiny', 'epochs': 10, 'jitter_strength': 0.3138757961845069, 'scheduler_step': 9, 'weight_decay': 5.130493991292702e-06, 'optimizer': 'Adam'}. Best is trial 4 with value: 0.940658557687414.
val Loss: 0.1738 Acc: 0.9408
성능 향상 X, 스탑 카운터 : 4

--- 얼리 스탑: 4 에폭 동안 성능 향상이 없어 훈련을 중단합니다. ---
Training complete in 55m 7s
Best val Acc: 0.9407
Epoch 1/15
----------
train Loss: 0.4716 Acc: 0.8337
val Loss: 0.3710 Acc: 0.8677
Epoch 2/15
----------
train Loss: 0.3500 Acc: 0.8741
val Loss: 0.3445 Acc: 0.8765
Epoch 3/15
----------
train Loss: 0.3238 Acc: 0.8826
val Loss: 0.3014 Acc: 0.8941
Epoch 4/15
----------
train Loss: 0.3067 Acc: 0.8893
val Loss: 0.2953 Acc: 0.8962
Epoch 5/15
----------
train Loss: 0.2928 Acc: 0.8938
[I 2025-12-13 09:59:27,760] Trial 5 pruned. 
val Loss: 0.2800 Acc: 0.9016
Trial pruned at epoch 4
Epoch 1/15
----------
train Loss: 0.5703 Acc: 0.8079
val Loss: 0.4145 Acc: 0.8587
Epoch 2/15
----------
train Loss: 0.3968 Acc: 0.8606
val Loss: 0.3752 Acc: 0.8676
Epoch 3/15
----------
train Loss: 0.3662 Acc: 0.8705
val Loss: 0.3574 Acc: 0.8756
Epoch 4/15
----------
train Loss: 0.3472 Acc: 0.8769
val Loss: 0.3343 Acc: 0.8833
Epoch 5/15
----------
train Loss: 0.3361 Acc: 0.8804
[I 2025-12-13 10:18:16,327] Trial 6 pruned. 
val Loss: 0.3336 Acc: 0.8813
Trial pruned at epoch 4
Epoch 1/15
----------
train Loss: 0.9893 Acc: 0.7000
val Loss: 0.5498 Acc: 0.8332
Epoch 2/15
----------
train Loss: 0.4943 Acc: 0.8450
val Loss: 0.4033 Acc: 0.8703
Epoch 3/15
----------
train Loss: 0.3975 Acc: 0.8685
val Loss: 0.3466 Acc: 0.8841
Epoch 4/15
----------
train Loss: 0.3520 Acc: 0.8826
